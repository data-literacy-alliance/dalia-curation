DALIA_ID,Authors,License,Link,Title,Community,Description,Discipline,FileFormat,Keywords,Language,LearningResourceType,MediaType,ProficiencyLevel,PublicationDate,TargetGroup,RelatedWork,Size,Version
ce5403d0-274f-4ba1-a59a-465ec876b83b,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520}",CC-BY-4.0,https://doi.org/10.11588/heidicon/1738716,"Folge 0: #arthistoCast der Name, Digitale Kunstgeschichte das Programm",,"Im Wissenschaftspodcast #arthistoCast dreht sich alles um die Digitale Kunstgeschichte. Dabei geht es um den Einsatz digitaler Methoden in der kunsthistorischen Forschung, also um die Frage, wie technische Entwicklungen für das Fach genutzt werden können und wie sich die Forschung im Zuge der Digitalisierung verändert hat.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Arbeitskreis Digitale Kunstgeschichte * Kunstgeschichte * Digital Humanities,de,PodcastSeries,audio,,2023-02-15,,,7.35 MB,1
4dc24159-27ce-424d-9edd-2febd995e739,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520}",CC-BY-4.0,https://doi.org/10.11588/heidicon/1740196,Folge 1: Die Geschichte der Digitalen Kunstgeschichte,,"Die Geschichte der Digitalen Kunstgeschichte ist nicht einfach zu fassen. Dabei steht die Frage im Raum, seit wann es die Digitale Kunstgeschichte überhaupt gibt. Mit meinem Gast, Prof. Dr. Hubertus Kohle von der LMU München, spreche ich über die frühen Anfänge und die ersten Meilensteine der Digitalen Kunstgeschichte in Deutschland. Dabei blicken wir gemeinsam zurück auf eine Zeit, in der die Computer noch keine Bilder wiedergeben konnten und Disketten eine wichtige Rolle gespielt haben. Dabei war der Einsatz des Computers in der Kunstgeschichte kein Selbstläufer. Gegenwind und Kritik, vor allem an den Kooperationspartnern aus der Wirtschaft, hat nicht nachgelassen. Wie steht es heute um das Verhältnis von Digitaler und “Traditioneller” Kunstgeschichte? Welche Projekte könnte man nun mit einer verbesserten Technologie wie künstlicher Intelligenz wieder aufleben lassen? Und wie schaffen wir es, die digitalen Verfahren und Methoden zu kommunizieren, um damit die Digitale Kunstgeschichte auch zu Professionalisieren?",https://w3id.org/kim/hochschulfaechersystematik/n092 * https://w3id.org/kim/hochschulfaechersystematik/n275 ,.mp3,Wissenschaftsgeschichte,de,PodcastSeries,audio,,2023-02-22,,isPartOf:https://doi.org/10.11588/heidicon/1738716,49.14 MB,1
a392b459-8f18-4fdd-a979-d52ab3da956f,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520}",CC-BY-4.0,https://doi.org/10.11588/heidicon/1744899,Folge 2: Kunstgeschichte und Daten?,,"In dieser Folge spricht Jacqueline Klusik-Eckert mit dem Historiker und Data Engeneer Robert Nasarek. Es geht um die Herausforderungen der Kunstgeschichte sowohl die Objekte als auch die kunsthistorische Forschung in Datenform zu bringen. Angefangen bei der Überlegung, was Daten überhaupt sind, muss auch kritisch hinterfragt werden, welche Informationen in Daten abgebildet werden und an welcher Stelle in der Forschung überhaupt erst von Wissen gesprochen werden kann. Mit vielen Beispielen aus seiner Arbeitspraxis erklärt er anschaulich, welche Vorüberlegungen überhaupt unternommen werden müssen und mit welchen Methoden man diese dann umsetzen kann, um Historisches in Datenform zu bringen. Daten in der Kunstgeschichte können aber auch mehr als nur eine Herausforderung für die Erfassung sein. Durch gut strukturierte, normierte und offene Daten entstehen neue Forschungsfragen. Mit den passenden methodischen Ansätzen, die durch datengestützt oder datengetriebene Forschungsdesigns erst ermöglicht werden, können wir ganz neue Perspektiven auf unsere Untersuchungsgegenstände, die Geschichte und die Wissenschaft Kunstgeschichte werfen.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,,de,PodcastSeries,audio,,2023-03-01,,isPartOf:https://doi.org/10.11588/heidicon/1738716,51.58 MB,1
650b8231-eea4-48ea-80a9-543a51c45717,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520}",CC-BY-4.0,https://doi.org/10.11588/heidicon/1747388,Folge 3: Vom Suchen und Finden – Information Retrieval,,"Wie oft sucht man etwas am Tag im Internet oder in Datenbanken? Auch wenn es da keine genauen Zahlen gibt, ist die Antwort auf jeden Fall: oft. Information Retrieval, also die Informationsrückgewinnung, sorgt dafür, dass wir die Informationen in großen, komplexen Datensammlungen überhaupt wiederfinden. Aber wie funktioniert das? In dieser Folge spricht Jacqueline Klusik-Eckert mit Dr. Lisa Dieckmann und Dr. Jürgen Hermes über das interdisziplinäre Fachgebiet Information Retrieval. Ist es nicht ein Problem, dass wir in einer Bildwissenschaft wie der Kunstgeschichte mit Texten suchen? Und woher weiß ich, ob ich alles gefunden habe, was in der Datensammlung drin steckt? Dr. Lisa Diekmann ist promovierte Kunsthistorikerin und Softwareentwicklerin und sorgt mit dem prometheus-Team dafür, dass wir nun schon seit 20 Jahren im prometheus-bildarchiv mit einer Suchanfrage in aktuell 121 Datensammunlungen suchen können. Dr. Jürgen Hermes ist Geschäftsführer des Instituts für Digital Humanities der Universität zu Köln und kennt sich mit sprachlicher Informationsverarbeitung und Suchmaschinen wie Google aus. https://prometheus-bildarchiv.de/de/about/index https://dh.phil-fak.uni-koeln.de/mitarbeiterinnen/wissenschaftliche-mitarbeiterinnen/dr-juergen-hermes Gemeinsam mit ihnen möchten wir herausfinden, was hinter dem Suchfeld passiert, warum man manchmal enttäuscht von den Ergebnissen ist und wie Suchmaschinen bei der Suche helfen, ohne dass man es merkt. Wir stellen auch die Frage, was eigentlich Relevanz ist und wie den unterschiedlichen Erwartungshaltungen von Benutzer*innen entgegenkommt.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Prometheus * Information Retrieval * Suchmaschine * ChatGPT * Google Search Console * ARTigo * Suchmaschinenoptimierung,de,PodcastSeries,audio,,2023-05-25,,isPartOf:https://doi.org/10.11588/heidicon/1738716,50.26 MB,1
ad7e5a4d-87e3-43a0-ba9b-6c62e235873d,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Bell, Peter * Schneider, Stefanie",CC-BY-4.0,https://doi.org/10.11588/heidicon/23729794,Folge 4: Visuelles Flanieren – Mit Computer Vision in großen Bildmengen suchen,,"Im Zuge der Digitalisierung von Museums- und Archivbeständen sind wir in der Kunstgeschichte mit einer enormen Menge heterogener Bilddatenbanken konfrontiert. Aber wie können wir uns diese großen Bilddatenmengen erschließen? Was ist visuelles Suchen und wie funktioniert die Technik dahinter? In dieser Folge spricht Jacqueline Klusik-Eckert mit Prof. Dr. Peter Bell und Stefanie Schneider, M.Sc., über das visuelle Suchen in großen Bilddatenmengen. Dabei geht es neben einer Reflexion über unsere Suchstrategien in der Kunstgeschichte auch um Prototypen für das visuelle Suchen. Hierbei werden in experimentellen Anwendungen unterschiedliche Verfahren des Computersehens, Computer Vision, erprobt. Angefangen bei der Frage, ob es visuelles Suchen überhaupt schon gibt, werden unterschiedliche Suchverhalten und Routinen besprochen, wie man sich großen Datenmengen nähern kann. Dabei wird klar, dass das visuelle Suchen mittels Computer Vision Verfahren eher einem mäanderndem Flanieren ähnelt und hilft, über unsere menschlichen Wahrnehmungsgrenzen hinauszugehen. Welche Rolle diese Hilfsmittel bei der Erschließung von unkategorisierten Datenmengen spielen und wie man sie auch zur Inspiration für neue Forschungsideen nutzen kann, wird im gemeinsamen Gespräch erörtert. Dabei gewinnt man einen Einblick in die Technik hinter der Benutzeroberfläche. Denn oft ist nicht klar, was ein Algorithmus als ""ähnlich” betrachtet oder warum gewisse Werke miteinander in eine Art Punktwolke, dem Skatterplot, gruppiert werden. Die beiden Experti*innen erklären die dahinterliegenden Verfahren und zeigen auch ihre Grenzen auf. Es wird klar, dass der Einsatz dieser digitalen Werkzeuge als Hilfsmittel auch immer mit einer Diskussion über facheigene etablierte Verfahren und Methoden des Recherchierens und Suchens einhergeht. Prof. Dr. Peter Bell ist Professor für Kunstgeschichte und Digital Humanities an der Philipps-Universität Marburg. In seiner Forschung beschäftigt er sich schon länger mit den Einsatzszenarien von Computer Vision für die Kunstgeschichte. In seiner Arbeitsgruppe wurde u.a. die Bildsuche imgs.ai von Fabian Offert entwickelt https://imgs.ai/. https://www.uni-marburg.de/de/fb09/khi/institut/lehrende-seiten-und-bilder/prof-dr-peter-bell Stefanie Schneider ist Wissenschaftliche Assistentin für Digitale Kunstgeschichte an der Ludwigs-Maximilians-Universität München. Als Fachinformatikerin und ausgebildete Anwendungsentwicklerin hat sie schon einige Prototypen für die Digitale Kunstgeschichte entwickelt und spricht über das Projekt „iART – Ein interaktives Analyse- und Retrieval-Tool zur Unterstützung von bildorientierten Forschungsprozessen“",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Information Retrieval * ChatGPT * Deep Learning * Conference on Pattern Recognition and Image Processing * Arbeitskreis Digitale Kunstgeschichte * Kunstgeschichte * Methodologie,de,PodcastSeries,audio,,2023-07-03,,isPartOf:https://doi.org/10.11588/heidicon/1738716,74.30 MB,1
7917b958-8b0f-449f-b073-d367b04af62f,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Messemer, Heike",CC-BY-4.0,https://doi.org/10.11588/heidicon/23777317,Folge 5: 3D-Rekonstruktionen im wissenschaftlichen Kontext,,"3D-Rekonstruktionen begegnen uns in der Kunstgeschichte an ganz unterschiedlichen Stellen. Mal sieht man sie in der Vermittlung von historischen Bauentwicklungen, mal als Modell für immersive Kamerafahrten durch den ursprünglichen Zustand von Architekturen oder Platzanlagen. In den seltensten Fällen wissen wir, wie diese 3D-Rekonstruktionen entstanden sind. Jacqueline Klusik-Eckert spricht mit Dr. Heike Messemer, Center for Open Digital Innovation and Participation (CODIP), über die Geschichte der 3D-Rekonstruktionen von Architektur und Platzanlagen. Dabei geht es genauso um die technischen Herausforderungen im Wandel der Zeit wie um die Frage nach der Akzeptanz der 3D-Modelle als neue Bildmedien in der Kunstgeschichte. Was macht eine wissenschaftliche 3D-Rekonstruktion aus? Wie sieht es mit der Nachvollziehbarkeit von Thesen oder Unsicherheiten aus? Kann ich einer Visualisierung vertrauen, wenn sie „aufgehübscht“ wurde? Der Mehrwert für eine interdisziplinär angelegte Forschung ist nicht von der Hand zu weisen. Können doch an den virtuellen Modellen unterschiedlichste Simulationen durchgeführt werden, um Thesen zu prüfen oder Hypothesen zu entwickeln. Auch die Nachnutzungsszenarien sind vielseitig. Und doch werden nur wenige 3D-Rekonstruktionen im Sinne einer guten wissenschaftlichen Praxis veröffentlicht. Welche Hürden es für die Publikation dieser besonderen Datenarten gibt, wird ebenfalls diskutiert. Personenseite von Dr. Heike Messemer: https://tu-dresden.de/codip/zentrum/team/heike-messemer-1",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,3D-Technologie * 3D-Grafik-Software * Dreidimensionale Rekonstruktion * Klosteranlage der Benediktinerabtei Cluny (Cluny) * Erweiterte Realität <Informatik> * QR-Code * Arbeitsgruppe Digitale Rekonstruktion,de,PodcastSeries,audio,,2023-08-09,,isPartOf:https://doi.org/10.11588/heidicon/1738716,53.34 MB,1
96c7c7b5-9d35-4e95-b9e8-42fafa81b9b4,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Kailus, Angela",CC-BY-4.0,https://doi.org/10.11588/heidicon/23789370,Folge 6: Normdaten in der Kunstgeschichte,,"In dieser Folge spricht Jacqueline Klusik-Eckert mit Angela Kailus M.A. und Julia Rössel M.A. über die Rolle von Normdaten in der kunsthistorischen Forschung und Praxis. Der Ursprung von Normdaten hängt mit einem bibliothekarischen Systematisierungsbestrebungen in den 1970er Jahren zusammen. Wie hat sich der Umgang und die Konzepte von Normdaten im Zuge der Digitalisierung verändert? Mit einem Blick hinter die Kulissen der Gemeinsamen Normdatei (kurz GND) werden die Zusammenhänge von Identifikationsnummer und den dahinterliegenden Informationen erklärt. Welchen Mehrwert für die eigenen Daten erzielt man durch die Verwendung von Normdaten? Für welche Begriffe bzw. Entitäten gibt es Normdaten? Wo findet man sie? Woher kommt dieses Wissen und wie muss man mit dem Normdatensatz umgehen? Wir sprechen auch über den Unterschied eines institutionell gepflegten und autorisierten Normdatensatzes (GND über die Deutsche Nationalbibliothek) im Vergleich zu crowd-based Normdatensätzen (Wikidata). Darüber hinaus stellt sich die Frage, inwieweit die Verwendung von Normdaten bereits Einzug in das Fach Kunstgeschichte gehalten hat. Wir beleuchten die Herausforderung für sammelnde Institutionen bei der Erfassung von Objekten und der Anreicherung der Sammlungsdaten mit Normdaten. Welche Standards helfen bei der Erfassung und wofür soll man den Aufwand mit Normdaten überhaupt betreiben? Dabei nehmen wir unterschiedliche Szenarien im Datenlebenszyklus unter die Lupe. Wo begegnen wir als Forscher*innen diesen Daten, wie können wir sie nachnutzen und welche Verantwortung haben wir selbst als Produzent*innen von Forschungsdaten, wenn es um die Anreicherung der eigenen Daten mit Normdaten geht? Angela Kailus M.A. ist stellvertretende Leiterin des Deutschen Dokumentationszentrums für Kunstgeschichte – Bildarchiv Foto Marburg, Philipps-Universität Marburg und Ansprechperson bei NFDI4Culture im Arbeitsbereich Standardisierung und Datenqualität. https://orcid.org/0000-0003-1514-2258 Julia Rössel M.A. ist Kunsthistorikerin und Mitarbeiterin an der Deutschen DigitalenBibliothek, Fachstelle Denkmalpflege, DDK, Marburg https://pro.deutsche-digitale-bibliothek.de/daten-liefern/fachstellen/fachstelle-denkmalpflege. Neben ihrer Promotion über “Wechsel der Mediensysteme – Graphische Sammlung und ihre digitale Übersetzung” hat sie sich in den Bereichen Digitalisierung und Museum, Datenqualität und Standards spezialisiert. https://orcid.org/0000-0002-5561-9674",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,GND * Getty Research Institute for the History of Art and the Humanities * LIDO <XML-Schema> * Wikidata,de,PodcastSeries,audio,,2023-08-23,,isPartOf:https://doi.org/10.11588/heidicon/1738716,58.57 MB,1
305db945-4314-4709-bcb1-e899d5e94d58,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520}",CC-BY-4.0,https://doi.org/10.11588/heidicon/23789438,Folge 7: AI Art und die Kunstgeschichte,,"In dieser Folge spricht Jacqueline Klusik-Eckert mit Dr. Fabian Offert über AI Art im Allgemeinen, wie sich das Genre mit den neuen Bildgeneratoren jüngst verändert hat und die dahinterliegenden KI-Verfahren. Dabei beleuchten sie schlaglichtartig die historischen Entwicklungen und die Herausforderungen für die Kunstgeschichte im Umgang mit den neuen Bildmedien. Schon lange vor der Veröffentlichung von Dall-E oder Midjourney nutzen Künstler*innen die Verfahren von Machine Learning und später Neuronalen Netzen bis zu generativen Modellen. Der Überbegriff AI Art umfasst Kunstwerke, die mithilfe von künstlicher Intelligenz und speziellen Algorithmen erstellt oder beeinflusst werden, wobei die Technologie entweder als Werkzeug für Künstler*innen dient oder autonom Kunstwerke generiert. Es umfasst eine breite Palette von Ausdrucksformen, die von algorithmisch gesteuerten Designs bis hin zu Werken reichen, die vollständig von KI-Systemen erzeugt werden. Das Genre ist aufgrund der heterogenen Werklage schwierig zu fassen. Doch mit dem öffentlichen Zugang zu den Verfahren über einfach zu bedienende Interfaces hat sich nicht nur das Genre AI Art geändert. Die neuen Bildgeneratoren lassen uns alle zu Künstler*innen werden: mit einem Prompt, einer Texteingabe an ein KI-System, werden Rechenprozesse angestoßen und neue Bilder generiert. Sie entstehen jedoch nicht in einem Vakuum, sondern sind Ergebnisse von Lernprozessen mit Millionen eingespeister Bilder. In dem Gespräch wird der Frage nachgegangen, wie wir mit diesen neuen Bildmedien in der Kunstgeschichte umgehen können. Was ist notwendig, um die dahinterliegenden Prozesse zu verstehen? Wie geht man beispielsweise mit Fragen des geistigen Eigentums um, wenn KI-Systeme von bestehenden Kunstwerken lernen? Und was hat die Mona Lisa damit zu tun? Wie beeinflusst die Verbreitung von ki-generierter Kunst den Kunstmarkt? Neben ethischen und rechtlichen Bedenken geht es aber auch um die Beziehung von Künstler*innen, Werk und Technik. Dabei wird klar, dass wir sowohl im bildwissenschaftlichen als auch gesellschaftlichen Diskurs mitten in einer Verhandlungsphase stecken. Wie gehen wir mit der Black Box Künstliche Intelligenz um? Was macht dieser neue Kanon und die versteckte, implizite Zensur hinter den Unser-Interfaces mit der Art uns Weise, wie wir diese Bilder verwenden und die Welt sehen? Es zeigt sich, dass vorherrschende Vorurteile durch die KI-Systeme verstärkt werden. Dabei wird auch deutlich, welche Verantwortung die Kunstgeschichte nun hat, die aktuelle Debatten mitzuführen. Dr. Fabian Offert ist Assistant Professor in History and Theory of Digital Humanities an der University of California, Santa Barbara. In seiner Forschung beschäftigt er sich schon lange mit den Wechselverhältnissen von Medien- und Kulturtheorie, Künstlicher Intelligenz und dem Einsatz von Computer Vision in den Geisteswissenschaften. https://zentralwerkstatt.org/",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Generative Computergraphik * OpenAI (Körperschaft) * Google * Digital Humanities * ImageNet,de,PodcastSeries,audio,,2023-10-03,,isPartOf:https://doi.org/10.11588/heidicon/1738716,64.30 MB,1
952606d4-7350-4a3b-ba2a-971169579700,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Petri, Grischka",CC-BY-4.0,https://doi.org/10.11588/heidicon/23793440,"Folge 8: (Digitales) Recht und Kunstgeschichte - von Schreckgespenstern, Hürden und dem Weg zu mündigen Nutzer*innen",,"In dieser Folge spricht Jacqueline Klusik-Eckert mit Dr. Dr. Grischka Petri über die vielen unterschiedlichen Rechtsverhältnisse in der Kunstgeschichte und dem digitalen Raum. In einem lockeren Rechtsgespräch erhält man einen Überblick über den Blumenstrauß an Rechtsformen, mit denen man in Berührung kommt, wenn es um die Erforschung des kulturellen Erbes geht. Petri plädiert dafür, die Bild- und Urheberrechte als Mitspracherechte zu verstehen. Die Forschenden kennen sich immer besser aus und wissen um die Knackpunkte. Doch die Rechtsformen ändern sich stetig weiter. Dabei schöpft er anekdotenreich aus einem großen Fundus von Praxisbeispielen. Dabei kommen Candida Höflers Fotografien von Rodin ebenso zur Sprache wie die von generativen Modellen erstellten Bilder. Wie ist unser Umgang mit den Urheberrechten bei künstlerischen Aufnahmen von gemeinfreien Werken? Und wo stehen wir gerade in der KI-Recht-Debatte? Aktuell fällt der Output von generativen Modellen noch aus dem Werkschutz heraus. Doch das könnte sich mit einem steigenden Verständnis der Verfahren auch ändern. Im Gespräch geht es auch um die rechtlichen Rahmenbedingungen für datengetriebene Forschung. Was ist bei der Beschaffung von großen Datenmengen noch erlaubt? Und welche Möglichkeiten der Publikation von Daten hat man, wenn sie einem nicht gehören? Der digitale Raum hat neue Spielformen von Bildern zutage gebracht. Während auf der einen Seite das Remixen und eben nicht auf ein Original reduzierte spannende, virale Kulturphänomene entstehen lässt, wächst das Interesse an einer Zertifizierung durch Blockchain-Technologie. Was sind die aktuellen Trends und welche Rolle spielt dabei Kunstmarkt? Neben den übergeordneten Debatten geht es auch immer wieder um die Eigenverantwortung als Wissenschaftler*in. Neben einem wissenden Umgang mit Bildern und Daten von sammelnden Institutionen liegt es doch an, wie zugänglich und rechtlich offen die eigenen Forschungsergebnisse zur Verfügung gestellt werden. Priv. Doz. Dr. Dr. Grischka Petri ist bei FIZ Karlsruhe und dort Mitarbeiter am Legal Help Desk von NFDI4Culture sowie Privatdozent für Kunstgeschichte an der Universität Bonn. Er beschäftigt sich schon lange mit Immaterialgüterrecht in verteilten Informationsinfrastrukturen in seinem Forschungsschwerpunkt über das Verhältnis von Recht und Kultur.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Urheberrecht * Data Mining * Non-Fungible Token * Creative Commons,de,PodcastSeries,audio,,2023-11-01,,isPartOf:https://doi.org/10.11588/heidicon/1738716,66.4 MB,1
1780c076-d593-48e1-bcba-74f9a3416741,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Simon, Holger * Sack, Harald",CC-BY-4.0,https://doi.org/10.11588/heidicon/23817821,Folge 9: Vernetztes Wissen - LOD und Knowledge Graph für die Kunstgeschichte,,"In dieser Folge spricht Jacqueline Klusik-Eckert mit Harald Sack und Holger Simon über den Knowledge Graph und seine Bedeutung für die Kunstgeschichte. Schon jetzt finden sich viele Informationen über Kulturgüter und Geschichte digital im Netz. Datenbanken und Repositories bieten zwar verstärkt Zugang zu Informationen, sind aber oft in isolierten Silos verstreut. Institutionen nutzen unterschiedliche Systeme zur Datenbereitstellung, was zu einer fragmentierten Landschaft führt. Meta-Datenbanken wie Europeana und die Deutsche Digitale Bibliothek versuchen, diese Fragmentierung zu überwinden, aber ihr Erfolg ist begrenzt. Es scheint, als bräuchten wir eine Meta-Meta-Datenbank, um diese Silos zu durchbrechen. Die Grundidee des Internets und das Konzept Linked Open Data (LOD) versprechen hier Abhilfe zu leisten. Die Herausforderung besteht darin, dieses vernetzte Wissen digital abzubilden. Hier kommt der Knowledge Graph ins Spiel. Im Rahmen des NFDI 4 Culture Projekts entsteht ein solcher Wissensgraph, über den ich mit Harald Sack und Holger Simon spreche. Wir diskutieren das Konzept hinter dem Wissensgraphen und seine Vision. Wir erkunden die Hürden jenseits der reinen Technik und fragen uns, ob die Kunstgeschichte bereit ist für ein offenes, vernetztes Wissen oder ob es dabei eher zu einer Wissenskluft kommt, weil gewisse digitale Kompetenzen nicht vermittelt werden. Abfragesprachen wie SPARQL spielen eine entscheidende Rolle bei der Datenabfrage im Knowledge Graph. Während in anderen Bereichen die Technologie des Knowledge Graphs schon länger im Einsatz ist – Google hat seit 2012 einen solchen Graphen etabliert –, befindet sich die Kunstgeschichte möglicherweise noch am Anfang dieser Entwicklung. GLAM-Institutionen (Galleries, Libraries, Archives, Museums) haben eine wichtige Rolle bei der Datenbereitstellung, müssen aber auch Anreize für den Austausch schaffen und erhalten. Für die Forschung eröffnet der Knowledge Graph neue Horizonte. Er ermöglicht nicht nur andere Fragestellungen und Visualisierungen von Datenmassen, sondern auch eine komplexere Anreicherung von Museumsinformationen. Aber letztendlich gewinnt der Mensch durch die Erkenntnisse, die aus diesen Daten gezogen werden. Von der Modellierung im Graphen bei der Digitalisierung bis hin zur Unterstützung durch die NFDI gibt es verschiedene Wege, sich einzubringen. Doch letztendlich liegt die Herausforderung darin, wie wir als Gemeinschaft von Forschenden und Kulturerbebewahrenden diese komplexe Datenlandschaft gemeinsam gestalten und nutzen können. Prof. Dr. Harald Sack isst Bereichsleiter für Information Service Engineering bei FIZ Karlsruhe – Leibniz-Institut für Informationsinfrastruktur und Professor am Karlsruher Institut für Technologie (KIT), Institut für Angewandte Informatik und Formale Beschreibungsverfahren (AIFB) mit der Forschungsgruppe „Information Service Engineering“. Und NFDI4Culture Co-Spockesperson von FIz Karlsruhe Prof. Dr. Holger Simon ist Sprecher im AK Digitale Kunstgeschichte, Geschäftsführer der Pausanio GmbH & Co. KG, Er ist außerplanmäßiger Professor an der Universität zu Köln und im Culture Steering Board NFDI 4 Culture.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Linked Data * Graphdatenbank,de,PodcastSeries,audio,,2023-12-05,,isPartOf:https://doi.org/10.11588/heidicon/1738716,64.02 MB,1
8d81fe78-d556-46e6-8332-5bf2b61973cf,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Hoppe, Stephan * Burioni, Matteo",CC-BY-4.0,https://doi.org/10.11588/heidicon/23820499,Folge 10: Virtual Reality und Kunstgeschichte – von Punktwolken zur illusionistischen barocken Deckenmalerei,,"In dieser Folge spricht Jacqueline Klusik-Eckert mit Prof. Dr. Stephan Hoppe und Dr. Matteo Burioni über den Einsatz von Virtual Reality (VR) bei der Erforschung barocker Deckenmalerei. Im Gespräch erhält man Einblick in die unterschiedlichen Abläufe und Kooperationen, die notwendig sind, um diese technischen Möglichkeiten für die Kunstgeschichte nutzbar zu machen. Die Unterhaltung beginnt mit der Grundlagenklärung, die den Begriffen wie Virtual Reality und Augmented Reality Raum gibt. Dabei wird deutlich, wie stark die Entwicklungen in der Kunstgeschichte auch mit der jüngsten Technikgeschichte zusammenhängen. Die Diskussion vertieft sich, indem die Potenziale und Herausforderungen von VR/AR in der Kunstgeschichte ausgelotet werden. Die Vision, historische Schauplätze virtuell auf höchstem wissenschaftlichen Niveau zu erschließen und zugänglich zu machen, wird durch Forschungsprojekte wie dem Akademieprojekt Corpus der barocken Deckenmalerei in Deutschland (CbDD) erprobt. Dabei wird nicht nur die Möglichkeit der Vermittlung von Kunstgeschichte betont, sondern auch der Erkenntnisgewinn durch neue Perspektiven und Forschungsmöglichkeiten im virtuellen Raum. Die Episode wirft auch einen kritischen Blick auf die derzeitige Integration von VR/AR in die Standardpraxis kunsthistorischer Institute. Hierbei wird deutlich, dass trotz vielversprechender Ansätze und Forschungen noch ein erheblicher Weg bevorsteht, bis diese Technologien flächendeckend in der Lehre und Forschung verankert sind. Der Höhepunkt des Gesprächs liegt in einem eindringlichen Appell: Die Kunstgeschichte muss enger mit Disziplinen wie Denkmaltechnologie, Archäologie und Informatik kooperieren. Nur so können die Entwicklung von VR/AR-Räumen und die Verantwortung für die Bewahrung des kulturellen Erbes vorangetrieben werden. Dabei wird betont, dass die Kunstgeschichte nicht nur von diesem Expertenwissen profitieren sollte, sondern auch als Treiber für innovative Entwicklungen fungieren kann. Prof. Dr. Stephan Hoppe ist Professor für Kunstgeschichte mit Schwerpunkt Bayerische Geschichte an der Ludwigs-Maximilian Universität München, ordentliches Mitglied des Instituts für Bayerische Geschichte und Leiter des Gesamtprojektes sowie Vorsitzender des Projektausschusses des Corpus der barocken Deckenmalerei. PD Dr. Matteo Burioni ist Projektkoordinator und Leiter der Arbeitsstelle München des Corpus der barocken Deckenmalerei in Deutschland) an der Ludwigs-Maximilian Universität München.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Virtual Reality * Erweiterte Realität <Informatik> * Neue Residenz (Bamberg) / Kaisersaal * Kompetenzzentrum Denkmalwissenschaften und Denkmaltechnologien,de,PodcastSeries,audio,,2024-01-02,,isPartOf:https://doi.org/10.11588/heidicon/1738716,67.24 MB,1
074742e2-da75-4b39-bb92-eb28342aa570,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Stalter, Julian",CC-BY-4.0,https://doi.org/10.11588/heidicon/23830633,"Folge 11: Digitale Kunst – ihre Geschichte, Akteur*innen und interaktiven Ansätze",,"In dieser Folge spricht Jacqueline Klusik-Eckert mit Julian Stalter über die lange Geschichte der digitalen Kunst und die vielen Akteur*innen dieser Kunstgattung. Die Digitale Kunst hat ihren Ursprung in den 1960er Jahren, als Künstler*innen begannen, Computer als kreatives Werkzeug zu nutzen. Der Durchbruch kam in den 1980er Jahren mit der Verbreitung personalisierter Computer und Software, die es Künstlern ermöglichten, digitale Medien als eigenständige künstlerische Ausdrucksform zu nutzen. Der Blick auf unterschiedliche Kunstwerke zeigt, wie eng die digitale Kunst auch mit der Technikgeschichte verbunden ist, sich aber auch von der Biologie inspiriert ist. Im Blogbeitrag zu dieser Folge findet man eine Liste aller genannter Künstlerinnen und Künstlern. Wo es möglich ist, wurden auch Aufzeichnungen der Werke als Links hinterlegt. Digitale Kunstwerke gehen oft über die traditionelle visuelle Wahrnehmung hinaus und integrieren Klang, Bewegung und Interaktivität. In teils experimentellen Installationen werden die Grenzen der Sinneswahrnehmung ausgelotet. Viele der multidimensionalen Werke fordern nicht nur die kunsthistorische Analyse heraus, sondern werfen auch Fragen nach der Rolle des Publikums und der Interaktion in der Kunst auf. Wichtige Institutionen, die sich mit Digitaler Kunst beschäftigen, sind das ZKM | Zentrum für Kunst und Medien in Karlsruhe, das sich auf die Schnittstelle von Kunst und Technologie konzentriert. Das Ars Electronica Center in Linz widmet sich der Förderung von Kunst und Technologie schon seit mehreren Jahrzehnten. Diese Institutionen und noch einige mehr spielen eine entscheidende Rolle bei der Dokumentation, Ausstellung und Erforschung digitaler Kunst und tragen dazu bei, ihre Anerkennung in der kunsthistorischen Landschaft zu fördern. Trotz ihrer kulturellen Bedeutung und des Einflusses auf zeitgenössische Kunst sind digitale Kunstformen in den kunsthistorischen Lehrplänen oft unterrepräsentiert. Die Debatte darüber, warum diese Gattung in der akademischen Welt nicht ausreichend gewürdigt wird, kreist um Fragen der Materialität, der Zugänglichkeit und der fehlenden Tradition. Die Trennung zwischen Kunst und Technologie sowie die Schwierigkeiten bei der Bewahrung und Ausstellung digitaler Werke sind ebenfalls Themen, die in diesem Kontext diskutiert werden. Julian Stalter M.A. ist Wissenschaftlicher Mitarbeiter im Projekt Reflection-based Artificial Intelligence in Art History, LMU München und beschäftigt sich in seiner Forschung mit Digitaler Kunst an der Schnittstelle von Naturnachahmung und Bio Art.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Computerkunst * Kunstgeschichte,de,PodcastSeries,audio,,2024-02-07,,isPartOf:https://doi.org/10.11588/heidicon/1738716,60.14 MB,1
f851f9d0-8600-4c1e-904f-696d05240211,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Glinka, Katrin * Heck, Kilia",CC-BY-4.0,https://doi.org/10.11588/heidicon/23842642,Folge 12: Digitalität und Kunstgeschichte – ein Theorie- und Metagespräch über aktuelle Debatten,,"In dieser Folge spricht Jacqueline Klusik-Eckert mit Katrin Glinka und Kilian Heck über die tiefgreifenden Veränderungen und aktuellen Debatten, die digitale Technologien in der Kunstgeschichte hervorgerufen haben. Dabei diskutieren die Gäste die unterschiedlichen Ebenen der Digitalität in der Kunstgeschichte: vom Scannen der Werke bis hin zu konkreten Anwendungen computationeller Verfahren eröffnet sich ein breites Spektrum. Es zeigt sich einmal mehr, wie vielschichtig die Perspektiven auf das Digitale sind. Es wird betont, dass viele in der Kunstgeschichte digitale Technologien noch immer auf die Digitalisierung von Material reduzieren. Die Potentiale digitaler Methoden werden dabei kaum gesehen oder vorschnell abgeurteilt. Unterstützungssysteme im Bereich Information Retrieval, die zu einer steigenden Zugänglichkeit und Auffindbarkeit von Forschungsmaterial sorgen, werden unreflektiert angenommen. Dagegen werden unter vorgehaltender Hand empirisch-statistische Verfahren als intransparent und verflachend abgeurteilt. Einig ist man sich hingegen wieder, wenn es um das Einsatzgebiet Provenienzforschung geht. Doch diese scheinbare Transparenz von etablierten Wissensspeichern muss hinsichtlich der historisch belasteten Beschreibungskategorien hinterfragt werden. Gleiches gilt für die Beschaffenheit der aktuell genutzten technischen Lösungen wie beispielsweise Sammlungsdatenbanken, die aktuell nicht vollumfänglich eine Vielfalt an Interpretationen und die Koexistenz von Widersprüchen ermöglichen. Hinzu kommt noch, dass sich Kunstgeschichtlerinnen und Kunstgeschichtler mit einer zunehmenden Komplexität und Vielfalt von Bildmaterial konfrontiert sehen. Das verlangt eine Anpassung der etablierten Analysemethoden und den Mut, sich außerhalb der traditionellen Komfortzonen zu bewegen. Es wird dafür plädiert, auch Fehler zu akzeptieren und tradierte, vorurteilsbehaftete Wissenssysteme kritisch zu reflektieren. Die Diskussion unterstreicht zudem die Bedeutung einer bildwissenschaftlichen Kompetenz und die anhaltende Notwendigkeit, die Fähigkeiten im Umgang mit modernen, auch KI-generierten Bildern zu schärfen. Schließlich wird auf die Rolle digitaler Technologien bei der Sicherung von Kulturerbe eingegangen, was die Relevanz und Dringlichkeit einer fortlaufenden Anpassung und Erweiterung der kunstgeschichtlichen Methoden und Curricula unterstreicht. Abschließend wird die Herausforderung der Förderung innovativer Projekte, die digitale Technologien nutzen, thematisiert. Es wird kritisiert, dass solche Projekte oft aufgrund mangelnder Förderlinien oder fehlendem Verständnis für digitale Ansätze abgelehnt werden. Trotz der Potenziale dieser Forschungsansätze bleibt die Akzeptanz und Integration in die klassische Kunstgeschichte eine Herausforderung. Ob dies auch einer (unbegründeten) Sorge um die eigene Daseinsberechtigung herrührt, muss unbeantwortet bleiben. Es ist im Gespräch jedoch deutlich geworden, dass gerade die Koexistenz klassischer und digitaler Methoden notwendig ist. Denn am Ende haben wir als Wissenschaftlerinnen und Wissenschafler doch das gleiche Ziel: Wissen schaffen. Dr. des. Katrin Glinka ist Kulturwissenschaftlerin und aktuell Head of HCC Data Lab an der Freien Universität Berlin bei der Forschungsgruppe Human-Centered Computing (HCC). In ihrer Dissertation »Festgeschrieben« - Kulturtechnische Manifestationen musealer Sammlungsordnungen und transformative Effekte digitaler Technologien. widmet sie sich den Wissensräumen unserer Sammlungen. ​​Prof. Dr. Kilian Heck ist Kunsthistoriker und hat den Lehrstuhl für Kunstgeschichte an der Universität Greifswald inne. Seine Forschungsschwerpunkte liegen in der europäischen Kunstgeschichte vom 16. bis ins 21. Jahrhundert, auf der Kunst nach 1800, insbesondere den Erscheinungen der Romantik im europäischen und transdisziplinären Vergleich.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,,de,PodcastSeries,audio,,2024-03-05,,isPartOf:https://doi.org/10.11588/heidicon/1738716,86.64 MB,1
e2dae505-b7c6-4e12-8940-b91e71cbb69b,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Freyberg, Linda",CC-BY-4.0,https://doi.org/10.11588/heidicon/23876695,Folge 14: Wissend visualisiert – Wissens- und Datenvisualisierungen in der Kunstgeschichte,,"In dieser Folge spricht Jacqueline Klusik-Eckert mit Dr. Linda Freyberg über die Herausforderungen und Potenziale der Wissens- und Datenvisualisierung in der Kunstgeschichte. Obwohl die Beschreibung und Interpretation visueller Systeme ein zentrales Element der Kunstgeschichte sind, fällt es vielen schwer, mit digitalen Visualisierungen umzugehen. Dazu gehört neben dem Interpretieren der Grafiken auch das Verwenden von Wissensvisualisierungen, um komplexes historisches Wissen wie zum Beispiel Objektbiographien darzustellen. Warum verwenden Kunsthistoriker diese Formen der Informationsübermittlung so selten? Fehlt das nötige Wissen oder die richtige Terminologie? Dr. Freyberg erklärt, dass Visualisierungen unterschiedliche Funktionen erfüllen können: explorativ zur Analyse oder interpretativ zur Erklärung. Dabei stellt sich die Frage, was eine effektive und gute Visualisierung ausmacht und ob der Kunstgeschichte eine neue Diagrammatik fehlt, um die Waage zwischen Komplexitätsreduktion und Wissensrepräsentation zu halten. Im Gespräch wird deutlich, dass viele unterschiedliche Expert*innen für die Erstellung von Visualisierungen notwendig sind, da heterogenes, spezifisches Fachwissen benötigt wird: Konzeption, technischer Aufbau und Nutzeroberfläche liegen am besten in der Hand eines interdisziplinär aufgestellten Teams. Viele Visualisierungen sind datengetrieben und darüber hinaus spezifisch für einzelne Projekte konzipiert, was eine Generalisierung mancher Anwendungen nicht möglich macht. Dabei sind Datenvisualisierungen ein mächtiges Kommunikationsmittel, um komplexe Sachverhalte verständlich zu machen. Sie ermöglichen es, Strukturen aufzuzeigen und große Datenmengen zugänglich zu machen. Obwohl diese Fähigkeiten oft als Zukunftskompetenzen gepriesen werden, gehören sie noch nicht zum Repertoire der Kunstgeschichte. Dr. Linda Freyberg zeigt dabei eindrucksvoll, wie Kunsthistoriker*innen zur Entwicklung und Interpretation von Visualisierungen beitragen können und warum man ein tiefes Domänenwissen braucht, um gute Wissensvisualisierungen zu schaffen. Dr. Linda Freyberg ist Wissenschaftlerin am DIPF Leibnitz Institut für Bildungsforschung und Bildungsinformation, Abteilung Bibliothek für Bildungsgeschichtliche Forschung. In ihrer Dissertation „Ikonizität der Information“ hat sie sich mit dem epistemischen Potenzial von Bildlichkeit und den unterschiedlichen Ausdrucksformen von Visualisierungen beschäftigt.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Visualisierung <Motiv>,de,PodcastSeries,audio,,2024-08-06,,isPartOf:https://doi.org/10.11588/heidicon/1738716,56.32 MB,1
ed7ae9ec-2ab6-42c2-bb96-410d9caa5968,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Wenzel, Michael * Iglesia, Martin de la",CC-BY-4.0,https://doi.org/10.11588/heidicon/23931857,Folge 15: Digitale Editionen für die Kunstgeschichte,,"In dieser Folge spricht Jacqueline Klusik-Eckert mit Michael Wenzel und Martin de la Iglesia über digitale wissenschaftliche Editionen in der Kunstgeschichte. Sie berichten aus dem DFG-geförderten Langzeitprojekt ‚Kommentierte digitale Edition der Reise- und Sammlungsbeschreibungen Philipp Hainhofers (1578-1647)‘. Zu Beginn wird deutlich, welchen Mehrwert wissenschaftliche digitale Editionen bieten. Neben der Bereitstellung der Originalpublikation als gescanntes Faksimile wird häufig parallel eine Ansicht für die Transkription und den editorischen Anmerkungsapparat geliefert. Diese Parallele liefert eine neue Transparenz. Dadurch können Forschende die Quellen direkt mit der Edition vergleichen, was einen Mehrwert im Forschungsprozess darstellt. Die technischen Anforderungen an digitale Editionen orientiert sich dabei stets an der Quellenlage und dem Editionsziel. Dabei spielt gerade die Gestaltung des User-Interface eine große Rolle. Es zeigt sich, dass digitale Editionen oft individuelle Lösungen benötigen, es keine standardisierte Herangehensweise gibt, gleichwohl man auf einen großen Erfahrungsschatz und Vorbilder zurückgreifen kann. Ein zentraler Punkt des Gesprächs ist die Frage, wie in den digitalen kunsthistorischen Editionen der Umgang mit unterschiedlichen Medien-, Datei- und damit auch Darstellungsarten gestaltet wird. Eine strukturierte Verknüpfung ist dabei das eherne Ziel. Auch die Herausforderungen der Langzeitarchivierung digitaler Editionen werden thematisiert. Neben der Sicherung der Daten über Repositorien sind es gerade die Interfaces, die uns aktuell vor eine Herausforderung stellen. Hierbei spielen sowohl technische als auch institutionelle Strukturen eine entscheidende Rolle, um die Zugänglichkeit digitaler Editionen zu gewährleisten. Dr. Michael Wenzel ist an der Herzog August Bibliothek Wolfenbüttel und im Projekt Kommentierte digitale Edition der Reise- und Sammlungsbeschreibungen Philipp Hainhofers (1578-1647) für die Konzeption und interne wissenschaftliche Leitung zuständig. Dr. Martin de la Iglesia ist an der Herzog August Bibliothek Wolfenbüttel und für die technische Umsetzung der digitalen Edition im Projekt Kommentierte digitale Edition der Reise- und Sammlungsbeschreibungen Philipp Hainhofers (1578-1647) verantwortlich.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,,de,PodcastSeries,audio,,2024-10-01,,isPartOf:https://doi.org/10.11588/heidicon/1738716,65.86 MB,1
0b68e2c2-4489-41be-bb40-e51776f401aa,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Merseburger, Maria * Gnyp, Anna",CC-BY-4.0,https://doi.org/10.11588/heidicon/23931859,Folge 16: Wissensgerechtigkeit auf Wikipedia: Kunsthistoriker*innen gestalten mit,,"In dieser Folge spricht Jacqueline Klusik-Eckert mit den Kunsthistorikerinnen Anna Gnyp und Maria Merseburger über das Verhältnis von Wikimedia und der Kunstgeschichte. Gemeinsam diskutieren sie, wie Wikipedia und Wikidata inzwischen zu wertvollen Ressourcen für kunsthistorische Forschung geworden sind und warum die aktive Mitgestaltung dieser Plattformen durch Fachwissenschaftler*innen unter dem Aspekt der Wissensgerechtigkeit wichtig ist. Anna und Maria geben Einblicke in ihre persönlichen Zugänge zur Wikipedia-Arbeit und erzählen, wie sich Vorurteile gegenüber der Enzyklopädie in der Wissenschaft gewandelt haben. Sie erläutern, wie Kunsthistoriker*innen durch gezielte Mitgestaltung Wikipedia-Wissen prägen können und welche Herausforderungen damit verbunden sind – darunter der Umgang mit Qualitätsstandards und Relevanzkriterien sowie die Frage nach dem „Gender Gap“, also der Unterrepräsentation weiblicher und marginalisierter Stimmen auf Wikipedia. Dabei wird auch die Arbeit der AG kuwiki vorgestellt, die mit mehreren Projekten die Sichtbarkeit kunsthistorischen Wissens auf Wikipedia fördert: Das „Living Handbook“ bietet eine Einführung in die Wikipedia-Arbeit für Kunsthistoriker. „Wikipedia in der Lehre“ zielt darauf ab, Studierende frühzeitig für die Plattform zu sensibilisieren und aktiv einzubinden. Und „Kuwiki Loves Monuments, too“ fördert die Dokumentation und Verbreitung von Bildern zu Denkmälern und Kulturgütern. Ein wichtiges Anliegen ist dabei die Wissensgerechtigkeit, um mehr Diversität auf Wikipedia und Wikimedia Commons zu erreichen. Das Gespräch beleuchtet auch die wachsende Bedeutung von Wikidata als datenbankgestützte Ressource, die zunehmend in digitalen kunsthistorischen Projekten genutzt wird. Anna und Maria zeigen auf, wie Museen, Archive und Bibliotheken von Wikidata und Wikimedia Commons profitieren können, um ihre Bestände öffentlich zugänglich zu machen und neue Vernetzungen zu schaffen. Abschließend plädieren sie für stärkere Kooperationen und „Best Practice“-Beispiele, die die Arbeit mit Wikimedia-Projekten in der Kunstwissenschaft festigen und bereichern können. Anna Gnyp, ist seit knapp zwei Jahren Mitglied der Arbeitsgemeinschaft. Aktuell ist sie Wissenschaftlerin im Datenkompetenzzentrum Sammlungen, Objekte, Datenkompetenz an der Humboldt-Universität Berlin. Das ist ein Verbundprojekt zum Aufbau eines Datenkompetenzzentrums für wissenschaftliche Universitätssammlungen. Dr. Maria Merseburger, ist seit Beginn im der AG kuwiki, hier unter dem Namen Karatecoop und aktuell Wissenschaftlerin am Museum für Kommunikation in Berlin.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,,de,PodcastSeries,audio,,2024-11-05,,isPartOf:https://doi.org/10.11588/heidicon/1738716,50.74 MB,1
ea1e868c-4f6f-46a7-b48f-eaa4c6b93e09,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Effinger, Maria * Pfisterer, Ulrich * Schelbert, Georg * Thomas, Kerstin",CC-BY-4.0,https://doi.org/10.11588/heidicon/23938908,"Folge 17: Memorandum ""Forschungs­daten in der Kunst­geschichte: 10 Thesen""",,"In dieser Folge spricht Jacqueline Klusik-Eckert mit Maria Effinger, Ulrich Pfisterer, Georg Schelbert und Kerstin Thomas, die als Initiator*innen des Memorandums einen Einblick in die aktuellen Herausforderungen und Chancen der kunsthistorischen Forschungsdaten geben. Link zum Memorandum und zum Zeichnen: https://kunstgeschichte.org/10-thesen-zu-forschungsdaten-in-der-kunstgeschichte/ Das Gespräch beginnt mit der Genese des Memorandums, beleuchtet die Motivationen und den dringenden Bedarf, der zu diesem wichtigen Schritt für das Fach Kunstgeschichte geführt hat. Es wird deutlich, dass die Definition, die Art und der Umgang mit Forschungsdaten in der Kunstgeschichte so vielschichtig sind wie die Disziplin selbst. Gemeinsam schauen sie mit unterschiedlichen Perspektiven auf die Notwendigkeit, Forschungsdaten nicht nur zu sammeln, sondern sie so aufzubereiten, dass sie zugänglich und nutzbar gemacht werden können. Dabei geht es auch um die institutionelle Verantwortung, Strukturen zu schaffen, die sowohl die Archivierung als auch die Beratung und Vernetzung unterstützen. Ein wichtiger Diskussionspunkt ist die Rolle der Künstlichen Intelligenz in der Forschung und wie das Memorandum darauf abzielt, KI-Strategien und -Richtlinien zu entwickeln, die es der kunsthistorischen Forschung ermöglichen, auf Augenhöhe mit aktuellen technologischen Entwicklungen zu bleiben. Abschließend reflektieren die Gäste über die nächsten Schritte, die die Community unternehmen sollte, um die im Memorandum skizzierten Ziele zu erreichen, und welche wissenschaftspolitischen Maßnahmen erforderlich sind. ​​Dr. Maria Effinger von der Universitätsbibliothek Heidelberg ist Leiterin der Abteilung ""Publikationsdienste"" und von ""arthistoricum.net - Fachinformationsdienst Kunst, Fotografie, Design sowie Co-Spokesperson von NFDI4Culture. Prof. Dr. Ulrich Pfisterer ist Professor für Kunstgeschichte an der Ludwig-Maximilians-Universität München und Direktor des Zentralinstituts für Kunstgeschichte, München. Dr. Georg Schelbert, Leiter der Photothek und Digital Humanities am Zentralinstitut für Kunstgeschichte, München, sowie Sprecher des Arbeitskreis Digitale Kunstgeschichte. Prof. Dr. Kerstin Thomas ist Professorin für Kunstgeschichte an der Universität Stuttgart und erste Vorsitzende des Deutschen Verbands für Kunstgeschichte.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Forschungsdaten * NFDI4Culture * NFDI4Memory * Kunstgeschichte <Fach>,de,PodcastSeries,audio,,2025-12-18,,isPartOf:https://doi.org/10.11588/heidicon/1738716,77.16 MB,1
dab9c560-9911-4c9a-b284-905a80cb46bd,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Hopp, Meike",CC-BY-4.0,https://doi.org/10.11588/heidicon/23959239,Folge 18: Provenienzforschung und das Digitale,,"In dieser Folge spricht Jacqueline Klusik-Eckert mit Meike Hopp über die aktuellen Entwicklungen und Herausforderungen der Provenienzforschung. Im Fokus stehen dabei digitale Hilfsmittel wie Datenbanken, die es ermöglichen, komplexe Objekt- und Personenbiographien besser sichtbar zu machen und Wissenssilos aufzubrechen. Während Datenbanken wie das Art Loss Register und die Lost Art Datenbank seit Jahren zur Verfügung stehen, haben sich die Methoden und Werkzeuge zur Erforschung der Herkunft von Kunstwerken und Kulturgütern rasant weiterentwickelt. Die zunehmende Öffnung von Sammlungsinstitutionen hilft dabei. Dennoch gibt es erhebliche Herausforderungen bei der Standardisierung, dem Zugang zu Daten und der internationalen Zusammenarbeit. Und dabei ist das Öffnen der Silos nur ein Aspekt des ganzen. Provenienzforschung ist nämlich viel mehr als nur genug Quellen zusammenzutragen. Datenauswertung im großen Stil verlangt Kompetenzen, die noch lange nicht zum Ausbildungskanon der Kunstgeschichte gehören. Ein besonderer Fokus liegt daneben auf der Notwendigkeit, Forschungsdaten und Quellen so aufzubereiten und zu präsentieren, dass sie nicht nur für Forschende, sondern auch für die breite Öffentlichkeit zugänglich sind. Dabei betont Meike Hopp die Bedeutung der Provenienzforschung, die über die reine Restitution von Kunstwerken hinausgeht. Es geht vermehrt um Teilhabe und Ermächtigung. Betroffenen Familien und Gemeinschaften erhalten erst durch optimal aufbereitete Daten – Stichwort Mehrsprachigkeit – und Interfaces die Möglichkeit, ihre eigene Geschichte aufzuarbeiten. Trotz signifikanter Fortschritte in der Provenienzforschung bangt der Forschungsbereich noch immer um eine nachhaltige Etablierung in der kunsthistorischen Ausbildungslandschaft. Prof. Dr. Meike Hopp, Juniorprofessorin für Digitale Provenienzforschung an der TU Berlin sowie Vorsitzendes des Arbeitskreis Provenienzforschung.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Provenienzforschung,de,PodcastSeries,audio,,2025-01-08,,isPartOf:https://doi.org/10.11588/heidicon/1738716,68.32 MB,1
4a1ef8c9-ece2-4b2c-8f4c-2199af90bec6,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520}",CC-BY-4.0,https://doi.org/10.11588/heidicon/23959241,Folge 19: Verstrickt – digitale Netzwerkforschung in der Kunstgeschichte,,"In dieser Folge spricht Jacqueline Klusik-Eckert mit Torsten Veit über historische Netzwerkforschung als Methode für die Kunstgeschichte. Dabei steht neben seiner eigenen Forschung auch die Frage im Raum, mit welchen digitalen Werkzeugen man sich hochkomplexen historischen Zusammenhängen nähern kann. Neben Programmen für die Anreicherung der Daten gehört dabei auch ein tieferes Verständnis für Datenvisualisierungen und Statistiken. Um komplexe Beziehungsgeflechte zu erforschen und zu verstehen, braucht es neben diesen digitalen Hilfsmitteln noch ein großes Verständnis von historischen Zusammenhängen und Sozialgeschichte. Torsten betont die Bedeutung der Netzwerkforschung, nicht nur als Methode zur Datenorganisation, sondern auch als einen Weg, um historische und kunsthistorische Zusammenhänge neu zu interpretieren. Dabei wird deutlich, dass Netzwerkanalysen weit über die reine Betrachtung sozialer Beziehungen hinausgehen, indem sie auch Objekte und Kunstwerke als zentrale Knotenpunkte innerhalb eines Netzwerkes behandeln können. Die Diskussion bietet auch eine kritische Auseinandersetzung mit den Limitationen und Herausforderungen der Netzwerkforschung, wie der Umgang mit lückenhaften historischen Daten und die Notwendigkeit, Netzwerkvisualisierungen sorgfältig zu interpretieren. Thorsten teilt seine Erfahrungen mit der praktischen Anwendung von Netzwerkanalyse-Tools wie Gephi und die Relevanz dieser Methoden für die kunsthistorische Forschung. Es zeigt sich in dem Gespräch deutlich, dass ein fundiertes Kontextwissen notwendig bleiben wird, um die Visualisierungen und Netze zu interpretieren. Torsten Veit M.A. ist Wissenschaftlicher Koordinator und Datenmanager des Herrenhauszentrum des Ostseeraums am Caspar-David-Friedrich-Institut, Universität Greifswald und Akademischer Mitarbeiter der Data Literacy an der FH Potsdam.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Europäisches Zentrum für Netzwerkforschung * Gephi,de,PodcastSeries,audio,,2025-02-05,,isPartOf:https://doi.org/10.11588/heidicon/1738716,40.72 MB,1
2c91835a-64cd-493b-ad48-0eb25e198a6c,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Schmidt, Antje * Hohmann, Georg",CC-BY-4.0,https://doi.org/10.11588/heidicon/23970043,Folge 20: Zwischen Server und Saal – die neuen Rollen der Sammlungsdigitalisierung,,"In dieser Folge wirft Jacqueline Klusik-Eckert mit Antje Schmidt und Georg Hohmann von #arthistoCast einen Blick hinter die Kulissen der Sammlungsdigitalisierung an Museen, die weit über das digitale Erfassen von Objekten hinausgeht. Dabei stellt sich heraus, dass sammelnde Institutionen in den letzten Jahren substanzielle Veränderungen und Anforderungen erlebt haben. Aus zwei unterschiedlichen Perspektiven und Erfahrungen an sehr unterschiedlichen Häuser teilen sie ihre Erfahrungen und lassen uns an den aktuellen und andauernden Herausforderungen teilhaben, die mit der Implementierung digitaler Strategien einhergehen. Obwohl die Digitalisierung nun schon ein paar Jahrzehnte durchgeführt wird, erfordern die heutigen digitalen Bemühungen eine umfassende Umgestaltung der Sammlungsverwaltung und neue Aufgabenbereiche, die mit öffentlicher Zugänglichkeit zu tun haben. Die Diskussion beleuchtet, wie der alltägliche Mangel an Ressourcen — sei es Serverkapazität oder spezialisiertes Personal — oft mit ambitionierten digitalen Vorhaben und Anforderungen kollidiert. Antje und Georg sprechen über die Notwendigkeit, über traditionelle Digitalisierungsprojekte hinauszudenken und stattdessen nachhaltige, integrative digitale Infrastrukturen zu schaffen, die nicht nur Sammlungsverwaltung betreffen, sondern auch die wissenschaftliche Forschung und öffentliche Interaktion erweitern. Ein Kernthema ist die Balance zwischen dem Wunsch nach innovativen digitalen Ansätzen und der realen Notwendigkeit, grundlegende digitale Infrastrukturen zu pflegen und zu erweitern. Sie diskutieren, wie digitale Tools genutzt werden können, um Sammlungen nicht nur zu konservieren, sondern sie lebendig und interaktiv zu machen. Es geht aber auch um Grenzen und die Frage der Notwendigkeit, wenn man die Nachhaltigkeit von „shiny“ Tools im Hinterkopf behalten muss. Das Gespräch bietet tiefgreifende Einblicke in die sich wandelnde Landschaft der Museumsdigitalisierung und wie diese Veränderungen die Rolle der Digitalisierungsabteilungen neu definieren. Dies verdeutlicht, dass erfolgreiche Digitalisierung mehr als nur technologische Updates erfordert; sie verlangt nach einem Kulturwandel, der Offenheit für neue Arbeitsweisen, eine klare Priorisierung und eine sich an Herausforderungen anpassenden, holistischen Strategie. Dr. Antje Schmidt ist Kunsthistorikerin und Leiterin des Bereichs Digitale Strategie und Projekte am MK und G, dem Museum für Kunst und Gewerbe in Hamburg. Georg Hohmann ist Leiter der Abteilung Deutsches Museum Digital des Deutschen Museums in München und studierter Kunsthistoriker und Informatiker.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Museum * Kunstgeschichte <Fach>,de,PodcastSeries,audio,,2025-03-05,,isPartOf:https://doi.org/10.11588/heidicon/1738716,151.55 MB,1
e8617c6b-2149-4334-b4ff-6d7f31be89c3,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Gries, Christian",CC-BY-4.0,https://doi.org/10.11588/heidicon/23970041,Folge 21: Zwischen App und Anspruch – die Aufgabenlandschaft der (digitalen) Vermittlung in Museen,,"In dieser Folge spricht Jacqueline Klusik-Eckert mit Christian Gries über die Vermittlung als Aufgabenfeld im Museum und welche Rolle digitale Formate dabei heute spielen. Das Gespräch beleuchtet, wie sich die Vermittlungsarbeit durch digitale Angebote in den letzten Jahrzehnten verändert hat und welche Herausforderungen und Chancen damit verbunden sind. Dabei wird klar: Digitale Vermittlung geht längst über klassische Medienstationen oder Audioguides hinaus. Heute geht es um hybride Besucherreisen, partizipative Formate und neue Rollenbilder für Museen, die sich zunehmend als aktive Wissenssender im digitalen Raum verstehen müssen. Aus der Diskussion geht auch hervor, dass digitale Vermittlungsformate nicht einfach die analogen ersetzen können und ein Bewusstsein für die Stärken der jeweiligen Medienformen entstehen muss. Dabei zeigt sich auch, dass sich digitale Elemente wie die MuseumsApp und der schon lange tot gesagt QR-Code doch etablieren konnten. Die aktuellen Herausforderungen nach einer experimentellen Phase während der Pandemie ist es nun, nachhaltige digitale Strategien zu entwickeln. Dabei spielt die Datenpflege und -archivierung genauso eine Rolle, wie die Frage von langfristiger Softwarehaltung. Museen stets eine Balance zwischen knappen Ressourcen, technologischem Fortschritt und inhaltlicher Qualität wahren. Ein weiterer Schwerpunkt sind die aktuellen Herausforderungen im Umgang mit Plattformabhängigkeiten und der Fragmentierung von Communities. Daraus ergibt sich die Notwendigkeit, digitale Produkte bewusst für die langfristige Nutzung zu entwickeln. Es wird auch diskutiert, wie Museen durch Kooperationen, Open-Source-Ansätze und Community-Arbeit ihre Reichweite und Relevanz nachhaltig stärken können. Diese Folge macht deutlich: Vermittlung im digitalen Raum ist kein Zusatz, sondern eine grundlegende Aufgabe, die neue Denkweisen und Strukturen im Museum erfordert. Dr. Christian Gries ist Leiter der Abteilung Digitale Museumspraxis und IT am Landesmuseum Württemberg.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Vermittlung * Museum * Kulturvermittlung,de,PodcastSeries,audio,,2025-05-07,,isPartOf:https://doi.org/10.11588/heidicon/1738716,142.54 MB,1
73e0577a-22b5-4efb-82c9-a2316a133def,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Hess, Mona",CC-BY-4.0,https://doi.org/10.11588/heidicon/23825275,Special zu Folge 10 #Perspektivwechsel: Digitale Denkmaltechnologie und Virtual Reality,,"In der ersten Sonderfolge von #arthistoCast steht die technische Perspektive auf das Erfassen von Kulturgütern im Mittelpunkt. Nachdem Jacqueline Klusik-Eckert in der 10. Folge mit ihren Gästen den kunsthistorischen Blick auf die viel diskutierten Technologien Virtual Reality (VR) und Augmented Reality (AR) geworfen hat, soll nun die technische Perspektive eingenommen werden. Im Gespräch mit Mona Hess von der digitalen Denkmaltechnologie gibt es Einblicke in die technischen Verfahren von Räumen und Objekten. Die technische Erfassung von Kulturgütern erfordert eine Vielzahl von Techniken, darunter aktive (Laserstrahl, Lichtmuster) und passive Sensoren (Kameras), sowie Methoden wie Photogrammetrie und Laserscanverfahren. Dabei werden Begriffe wie Geomatic Engineering, Reality Capture erklärt, und die Vorteile einer optischen, berührungsfreien Aufnahme bei der Erfassung von Räumen und Objekten erläutert. Es zeigt sich dabei deutlich, dass es mit dem Scannen allein nicht getan ist. Neben der Nachbereitung der Daten gehört auch die Langzeitarchivierung zu den aktuellen Herausforderungen. Doch wo können diese vielseitigen Kompetenzen erlernt werden? Da der Bedarf an Fachleuten mit interdisziplinären Kompetenzen zwischen Ingenieurswissenschaften, Informatik, Naturwissenschaften, Materialwissenschaften und Kunstgeschichte stetig wächst, wurde ein eigener Masterstudiengang etabliert. Insgesamt zeigt die Sonderfolge, dass die digitale Kunstgeschichte eine Brücke zwischen verschiedenen Fachrichtungen schlägt. Es wird deutlich, dass die Erfassung und Digitalisierung von Kulturgütern nicht nur kunsthistorisches Interesse bedient, sondern auch technische Innovationen vorantreibt. Der Blick auf die Herausforderungen der Datenverarbeitung und Langzeitarchivierung betont die Notwendigkeit, nicht nur die Erfassungstechniken zu beherrschen, sondern auch die umfassende Verarbeitung und Bewahrung der digitalen Daten im Blick zu haben. Prof. Dr. Mona Hess ist Lehrstuhlinhaberin des Lehrstuhls für Digitale Denkmaltechnologien an der Universität Bamberg. In ihrer Forschung bewegt sie sich an der Schnittstelle von naturwissenschaftlichen Technologien und geisteswissenschaftlichen Fragestellungen.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,3D-Scanner * Residenz Ansbach * Virtual Reality * Laserscanner,de,PodcastSeries,audio,,2024-01-22,,isPartOf:https://doi.org/10.11588/heidicon/1738716,38.5 MB,1
1f779793-9e43-4306-80f5-7fd02c4b0ce8,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Maier, Andreas * Meyer, Roland * Huemer, Christian",CC-BY-4.0,https://doi.org/10.11588/heidicon/23868497,Special #2: Ausschnitte aus dem Forum Digitale Kunstgeschichte auf dem 37. Kongress für Kunstgeschichte,,"In dieser Sonderfolge des #arthistoCast verlässt Jacqueline Klusik-Eckert das Aufnahmestudio und gibt einen Zusammenschnitt des Forums Digitale Kunstgeschichte wieder, das während des 37. Kongresses für Kunstgeschichte in Erlangen am 16.03.2024 stattfand. Das Forum, von Jacqueline und Peter Bell konzipiert, konzentrierte sich auf die Auswirkungen und Möglichkeiten künstlicher Intelligenz in der Kunstgeschichte. Unter dem Motto “Raum für KI – Bildgeneratoren und Wissensmaschinen. Die KI-Debatte im Fachkontext” waren die drei Gäste Andreas Maier, Roland Meyer und Christian Hümer eingeladen, um mit ihnen aus unterschiedlichen Perspektiven auf die aktuellen Debatten zu schauen. Die Podiumsdiskussion, geprägt von den drei Experten aus den Bereichen Technik, Theorie und Praxis, beleuchtete, wie KI-Verfahren bereits in der Kunstgeschichte angewendet werden und was sie für das Fach bedeuten. Es wurden konkrete Beispiele und laufende Projekte vorgestellt, um ein umfassendes Verständnis der Materie zu fördern. Zudem wurden kritische Fragen zur Zukunft der KI in der Kunstgeschichte gestellt, einschließlich ethischer Überlegungen und der Rolle von KI in der Forschung und Lehre. Diese Episode gibt nicht nur einen Einblick in die Veranstaltung für diejenigen, die nicht teilnehmen konnten, sondern bietet auch einen Startpunkt für weiterführende Diskussionen über die Rolle der KI in der Kunstgeschichte. Im zugehörigen Blogbeitrag findest du zusätzliche Ressourcen und Links zu den Projekten, die während des Forums vorgestellt wurden. Prof. Dr.-Ing. habil. Andeas Maier ist Leiter des Pattern Recognition Labs an der FAU Erlangen-Nürnberg und hat in unterschiedlichen Projekten den Einsatz von Pattern Recognition in der Kunstgeschichte erprobt. Dr. Roland Meyer ist wissenschaftlicher Mitarbeiter am SFB »Virtuelle Lebenswelten« an der Ruhr-Universität Bochum und forscht über die Theorie generierter Bilder und den Einsatz von KI-Verfahren. Dr. Christian Huemer ist Hauptabteilungsleiter des Research Center am Belvedere, Speaker des DArtHist Austria und hat zahlreiche digitale Projekte im Museum betreut.",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Künstliche Intelligenz * Kunstgeschichte,de,PodcastSeries,audio,,2024-03-16,,isPartOf:https://doi.org/10.11588/heidicon/1738716,60.88 MB,1
de4a4fb1-ee2e-4e7e-9b4d-c4978753cd20,"Klusik-Eckert, Jacqueline : {https://orcid.org/0000-0002-0969-2520} * Akkermann, Miriam * Kurz, Susanne * Thiel, Sonja",CC-BY-4.0,https://doi.org/10.11588/heidicon/23873951,"Special #3: NFDI4Culture Cultural Community Plenary 2024, Podiumsdiskussion ""Generative KI-Modelle und Forschungsdaten: Chancen und Herausforderungen""",,"In dieser Sonderfolge des #arthistoCast sendet Jacqueline Klusik-Eckert live von der virtuellen Podiumsdiskussion mit ihren Gästen Miriam Akkermann, Susanne Kurz und Sonja Thiel, die im Rahmen des 4. Culture Community Plenary von NDFI4Culture am 6. Juni 2024 stattgefunden hat. Unter dem Motto „Generative KI-Modelle und Forschungsdaten: Chancen und Herausforderungen“ diskutierte sie mit den Expertinnen die aktuellen Entwicklungen im GLAM-Bereich (Galerien, Bibliotheken, Archive, Museen). Dabei bot das Gespräch wertvolle Einblicke aus dem Bereich Museum, Musikwissenschaft und Forschungsdaten. Ein zentrales Thema war die Frage, wie generative KI-Modelle in der Kulturforschung eingesetzt werden können, ohne die Kontrolle und Transparenz zu verlieren. Es wurde betont, dass es wichtig sei, die technischen Prozesse und die Daten, die hinter diesen Modellen stehen, zu verstehen und zu hinterfragen, um eine aufgeklärte Nutzung zu gewährleisten. Dies verlangt sowohl die Entwicklung passgenauer Modelle als auch die Etablierung benutzerfreundlicher Anwendungen. Das Gespräch beleuchtete die vielseitigen Anwendungsmöglichkeiten von KI-Systemen im Kulturbereich. So diskutierten die Teilnehmerinnen unter anderem über die Einsatzpotenziale von Chatbots in Museen, die Herausforderungen der Generierung und Archivierung von Computermusik sowie die ethischen Implikationen und die Notwendigkeit von Transparenz bei der Nutzung kommerzieller KI-Modelle. Ein weiteres zentrales Thema war die Bedeutung von Vertrauen in die Arbeit von Institutionen beim Umgang mit digitalen Objekten, insbesondere im Hinblick auf generierte Medien. Es wurde betont, dass die Kennzeichnung von ordnungsgemäß transformierten Materialien und die Bereitstellung von Metadaten essenziell sind, um die Integrität und Authentizität digitaler Forschungsgrundlagen zu sichern. Die Diskussion verdeutlichte, dass generative KI-Modelle nicht nur neue Möglichkeiten eröffnen, sondern auch neue Fragen aufwerfen, die einen kritischen Diskurs und eine aufgeklärte Nutzung erfordern. Die Expertinnen forderten eine realistische Betrachtung der Technologie und ihrer Möglichkeiten sowie eine kontinuierliche Reflexion über die ethischen Implikationen ihres Einsatzes. Prof. Dr. Miriam Akkermann ist empirische Musikwissenschaftlerin und hat an der FU Berlin die Ernst-von-Siemens Musikstiftungsprofessur übernommen. Sie hat sich bereits seit der Promotion mit den Wechselbeziehungen von Algorithmus und Improvisation auseinandergesetzt. In ihrer Forschungstätigkeit interessiert sie sich auch für die Archivierung und Aufführbarkeit von Computer Musik. ORCID: 0000-0001-7154-7917 Susanne Kurz M.A. ist Dozentin für Medieninformatik und Digital Humanities an der Universität zu Köln. Ihre wissenschaftliche Arbeit umfasst die vielschichtige Repräsentation, Modellierung und technische Abbildung von Vertrauen in digitale Objekte des Kulturerbes, sowie den damit verbundenen Herausforderungen für die akademische Forschung in einer frühen postnatalen KI-Gesellschaft. ORCID: 0000-0002-2824-1485 Sonja Thiel M.A. ist freiberufliche Wissenschaftlerin und war als digitaler Katalysator für Künstliche Intelligenz am Badischen Landesmuseum in Karlsruhe tätig. Sie hat einen Hintergrund in Geschichte und Philosophie und hat als Kuratorin für partizipative Prozesse in kulturhistorischen Museen gearbeitet. Ihre Arbeit konzentriert sich auf die Überschneidungen zwischen Museologie, partizipativer kuratorischer Praxis und offener digitaler Bildung. ORCID: 0000-0002-0443-3685",https://w3id.org/kim/hochschulfaechersystematik/n092,.mp3,Künstliche Intelligenz * Kunstgeschichte,de,PodcastSeries,audio,,2024-06-06,,isPartOf:https://doi.org/10.11588/heidicon/1738716,69.14 MB,1
